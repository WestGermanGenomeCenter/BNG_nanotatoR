Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                count    min threads    max threads
---------------  -------  -------------  -------------
add_to_database        1              1              1
annotate               1              1              1
convert                1              1              1
filter                 1              1              1
total                  4              1              1


[Mon Aug 23 17:27:41 2021]
Job 3: converting input/43781_assembly_151_variants_combine_filters_inMoleRefine1.smap with input/43781_assembly_151_variants_combine_filters_inMoleRefine1_header.tx ...

Terminating processes on user request, this might take some time.
[Mon Aug 23 17:27:41 2021]
Error in rule convert:
    jobid: 3
    output: converted/43781_assembly_151_variants_combine_filters_inMoleRefine1_converted.smap
    log: logs/43781_assembly_151_variants_combine_filters_inMoleRefine1_conversion.log (check log file(s) for error message)
    shell:
        Rscript scripts/smap_converter.R input/43781_assembly_151_variants_combine_filters_inMoleRefine1.smap input/43781_assembly_151_variants_combine_filters_inMoleRefine1_header.tx converted/43781_assembly_151_variants_combine_filters_inMoleRefine1_converted.smap 2>&1 | tee logs/43781_assembly_151_variants_combine_filters_inMoleRefine1_conversion.log
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: /home/daric/work_WGGC/SV_annotation/sv_nanotation_snake/.snakemake/log/2021-08-23T172741.502629.snakemake.log
