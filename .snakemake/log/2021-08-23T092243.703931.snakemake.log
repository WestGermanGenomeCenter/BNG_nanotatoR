Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                count    min threads    max threads
---------------  -------  -------------  -------------
add_to_database        1              1              1
annotate               1              1              1
convert                1              1              1
extract_header         1              1              1
filter                 1              1              1
total                  5              1              1


[Mon Aug 23 09:22:43 2021]
Job 4: extracting header of input/Sample02_assembly_152_variants_combine_filters_inMoleRefine1.smap ...

[Mon Aug 23 09:22:43 2021]
Finished job 4.
1 of 5 steps (20%) done

[Mon Aug 23 09:22:43 2021]
Job 3: converting input/Sample02_assembly_152_variants_combine_filters_inMoleRefine1.smap with input/Sample02_assembly_152_variants_combine_filters_inMoleRefine1_header.tx ...

Terminating processes on user request, this might take some time.
Cancelling snakemake on user request.
